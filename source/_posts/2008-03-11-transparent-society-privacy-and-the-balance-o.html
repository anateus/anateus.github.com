---
permalink: /transparent-society-privacy-and-the-balance-o/index.html
layout: post
title: Transparent Society, Privacy, and the Balance of Power
published: true
categories: []
---
Recently <a href="http://en.wikipedia.org/wiki/Bruce_Schneier">Bruce Schneier</a> posted <a href="http://www.wired.com/politics/security/commentary/securitymatters/2008/03/securitymatters_0306">a debunking of the idea of a Transparent Society</a> (such as put forward by <a href="http://en.wikipedia.org/wiki/David_Brin">David Brin</a>). He argues that the while the more open exchange of information in society can lead to a power balance, existing power structures mean that those already powerful will benefit most from disclosure. Here's a quote near the top:

<blockquote>You cannot evaluate the value of privacy and disclosure unless you account for the relative power levels of the discloser and the disclosee.

If I disclose information to you, your power with respect to me increases. One way to address this power imbalance is for you to similarly disclose information to me. We both have less privacy, but the balance of power is maintained. But this mechanism fails utterly if you and I have different power levels to begin with.

An example will make this clearer. You're stopped by a police officer, who demands to see identification. Divulging your identity will give the officer enormous power over you: He or she can search police databases using the information on your ID; he or she can create a police record attached to your name; he or she can put you on this or that secret terrorist watch list. Asking to see the officer's ID in return gives you no comparable power over him or her. The power imbalance is too great, and mutual disclosure does not make it OK. </blockquote>

As a frequent advocate of transparency as a way to normalize power in a society I must clarify my position in light of these valid objections. Schneier very correctly points to "The Transparent Society" as an utopian ideal. Perhaps it is a tired trope, but I'd like to point out that "utopia" originally meant "no place". That is, a place of total transparency and thus balanced power is an unachievable goal on its face.

I advocate movement toward such a society in a way that---unlike Schneier assumptions about such ideas---maintains as much power as possible within the hands of those currently on the lower end of the scale. This is where cryptography and other protectors of your information/privacy come in. I disagree with Schneier's claim that there is an inherent value in privacy; it is only there to equalize the balance.

Thus, believing in transparency doesn't mean you accept a "me first" approach. One does not necessarily expose oneself first in the hope of the powerful following suit. Rather, the <a href="http://en.wikipedia.org/wiki/Power-knowledge">power-knowledge</a> of the elite must be systematically broken down while protecting our own zealously all the while. Eventually, we should reach a sort of detente in the matter.

There are common-good externalities to transparency that are substantial, but as Schneier warns, we must equalize initial powers as much as possible before going "clear". Otherwise, the individual benefits are small, and the opportunity for exploitation increases.

<em>Caveat Patefactor!</em>
